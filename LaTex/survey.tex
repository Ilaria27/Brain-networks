\chapter{Survey}
\label{chap:2} 

\section{All methods}
In this chapter there will be a wide description of the state-of-the-art about \textit{brain network classification}. For sake of clarity, we divide the methods in 3 different classes: Deep Learning, Statistical Fingerprints and Machine Learning. In order to compare them, we have performed an experimental analysis, whose results are described in Chapter \ref{chap:3}.

\subsection{Deep Learning}
\paragraph{GroupINN: Grouping-based Interpretable Neural Network for Classification of Limited, Noisy Brain Data}\
\vspace{0.5cm}

This state-of-the-art of Yan Y. et al \cite{groupinn} proposes a grouping-based interpretable neural network model, GroupINN, that classifies cognitive performance with 85\% fewer parameters than baseline deep models, while also identifying the most predictive brain subnetworks within several task-specific contexts. In the design of the neural network is included the idea of node grouping. In this way the model learns the node grouping and extracts the graph features jointly.
\vspace{0.5cm}

The problem statement is: given a set of subjects, each with corresponding fMRI data and a label associated with a certain phenotype, we seek to devise an efficient, interpretable, and parsimonious neural network model that can predict each phenotype with high accuracy.
\vspace{0.5cm}

To reduce the number of parameters used in the model, they adopted the idea of multi-graph clustering (where the goal is to find a common clustering across multiple graphs) to summarize the original graph into a supergraph with each cluster as a supernode. 
\vspace{0.5cm}

The neural network is formed by three different types of layers: node grouping layer, graph convolutional layer and fully connected layer. The node grouping layer is designed to “hide” the non-indicative (‘noisy’) edges by grouping them into a cluster, thus highlighting the indicative edges: two nodes are assigned to different groups if their connection is identified as important.
Graph convolutional layers are used to capture the structure of the supergraph.
\vspace{0.5cm}

The neural network is also divided in two branches, one processes the positive graphs and one the negative ones. 
All in all, the architecture consists of three kinds of layers and two branches. 
The input graph is the correlation matrix $W$. The first layer is a dimensionality reduction layer and the output is a matrix $W^{s}$ representing the supergraph. Following the dimensionality reduction layer, three graph convolutional layers are used. At last, the positive and negative outputs of the previous layer are concatenated, flattened and sent to the fully connected layer (with softmax activation). The design of the model is represented in Figure \ref{fig:diagram5}.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.65]{Immagini/Groupinn1.PNG}
	\caption{Structure of GroupINN Neural Network.}
	\label{fig:diagram5}
\end{figure}

Regarding the experimentation part, they used a dataset taken from Human Connectome Project 1200 (HCPt) \cite{hcp}. 
This dataset consists of 966 subjects to which has been measured brain activity, through fMRI, while they were performing specific tasks. The four task-based datasets used in this experiment are: \textit{Emotion, Gambling, Social} and \textit{Working Memory}. It is divided in 90\% train/validation set and 10\% testing set. For the evaluation they take in consideration \textit{accuracy} and the \textit{runtime}. Comparing their method, they found out that it is faster and with less parameters than other works, so it is more interpretable, as well as having good accuracy.

\paragraph{Deep Learning-based Pipeline to Recognize Alzheimer’s Disease using fMRI Data}\
\vspace{0.5cm}

S. Sarraf et al. \cite{Sarraf066910} built a Neural Network, specifically a Convolutional Neural Network (\textbf{CNN}) for classification of clinical data, in particular they tested it for Alzheimer disease. Their dataset is composed of a group of people affected by Alzheimer and a control group. They where scanned with resting-state FMRI, and after a preprocess, the data consisted of images of functional information. 
\vspace{0.5cm}

CNNs in general are used to study images, and are composed of Pooling layers, Normalization layers, Fully Connected layers and Convolutional layers. Convolutional layers help to maintain the spacial order of the input they are working on, obviously very important on images, and these layers consist on filters applied to these images. In this case they used an already implemented CNN called LeNet-5 (by Y. LeCun et al \cite{726791}), and adjusted it for fMRI data. The data in input were 2D images, that were labeled for binary classification, as shown in Figure \ref{fig:diagram7}.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=1]{Immagini/deep-learning1.PNG}
	\caption{CNN LeNet-5 structure adjusted for fMRI input data.}
	\label{fig:diagram7}
\end{figure}

The experiment ended up with a very high accuracy (96.8588\%) and a very low learning rate, meaning that it is a valid tool, even if on one hand it is a very complicated model, has many parameters and hyperparameters to tune and could have GPU memory problems.

\paragraph{Functional Brain Network Classification for Alzheimer’s Disease Detection with Deep Features and Extreme Learning Machine}\
\vspace{0.5cm}

X. Bi et al \cite{Bi2019FunctionalBN} designed two deep learning methods of functional brain network classification. More precisely they concentrate their work on Alzheimer disease detection. The first model is a Convolutional learning method, that learns the deep regional-connectivity features. The second is a Recurrent learning method, learning deep adjacent positional features. So, both the learning methods are Neural Networks. They also implemented an Extreme Learning Machine (ELM) to improve the learning ability, and is implemented in the learning methods.
\vspace{0.5cm}

Both the deep learning methods take as input a graph matrix, i.e. the adjacency matrix of each patient. 
The Convolutional Learning method (Figure \ref{fig:diagram8}) is composed of a Convolutional layer, Activation function, Pooling layer, Fully Connected layer and a Decision layer. It is in the Convolutional layer that the features are extracted, while in the decision layer, with a \textit{Softmax} function, are generated the labels of each brain network.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.5]{Immagini/functional1.PNG}
	\caption{Structure of the Convolutional Learning method.}
	\label{fig:diagram8}
\end{figure}

To the Recurrent learning method (Figure \ref{fig:diagram9}) is given as input a row o more of the graph matrix at each time step, until all the rows are learned. It is mainly composed of two parts, the recurrent structure and the classification structure. 
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.5]{Immagini/functional2.PNG}
	\caption{Structure of the Recurrent Learning method.}
	\label{fig:diagram9}
\end{figure}

The complexity of these two models is in the fully connected layer, where there is an high computation for the parameters tuning. For this reason is built the ELM layer. It is much faster and gives good generalization performance. So, the deep features are extracted, convolutional or recurrent ones, and are given to the ELM layer, that produces the output labels (Figure \ref{fig:diagram10}). 
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.5]{Immagini/functional3.PNG}
	\caption{Structure of ELM Classifier with both learning methods.}
	\label{fig:diagram10}
\end{figure}

For the experiments they compared their methods with shallow methods. They saw that, with ELM, both neural networks performed better than without ELM, but ELM also brings performance fluctuation. Anyway, they performed much better than shallow methods. Recurrent method, in particular, is slightly better that the Convolutional one, but takes much more training time. Instead, Convolutional learning method, having more parameters to tune, reaches with more difficulty the optimal performance.

\subsection{Statistical Fingerprints}
\paragraph{Explainable Classification of Brain Networks via Contrast Subgraphs}\
\label{par:1}
\vspace{0.5cm}

In this work of Bonchi F, Lanciano T. and Gionis A. \cite{lanciano2020cs} they introduce an approach for classifying brain networks based on extracting contrast subgraphs, i.e., a set of vertices whose induced subgraphs are dense in one class of graphs and sparse in the other. The model is extremely simple, with just one parameter, excellent interpretability and good classification accuracy. What they want to improve or add, differently from others methods, are the node-identity awareness, black box effect and high number of parameters. With \textbf{node-identity awareness} is meant to take in consideration that a specific vertex corresponds to the same ROI in all the input graphs. This is very important to find similarities among the input networks. The majority of the models have a \textbf{black box effect}, meaning that are complicated to understand how to use them, and their parameters. It should be crucial to make it understandable for neuroscientists that need these tools. Even the \textbf{high number of parameters} could be a problem, for overfitting and for tuning them. 
\vspace{0.5cm}

In their experimentation, each individual is represented by an undirected unweighted graph with $|V|$ = 116 vertices, that are the ROIs. They propose two problems regarding contrast-subgraphs, but in the experiments chapter \ref{chap:3} we will employ only the first one. \textit{Problem 1} states that given the observations of condition group - affected by autism - and control group, and the corresponding summary graphs, they seek to find a subset of vertices that maximizes the contrast-subgraph objective, so to find a set of vertices whose induced subgraph is dense in the summary graph of $G^{\mathcal{A}}$ - condition group - and sparse in summary graph $G^{\mathcal{B}}$ - control group. It can be summarised in the following equation:
\vspace{0.5cm}

\begin{equation}
	\delta(S)=e^{\mathcal{A}}(S)-e^{\mathcal{B}}(S)-\alpha\left(\begin{array}{c}
		|S| \\
		2
	\end{array}\right)
\end{equation}
where $ e^{\mathcal{A}}(S) $ and $ e^{\mathcal{B}}(S) $ correspond to the number of edges in the subgraph induced by $ S $ in the summary graphs $G^{\mathcal{A}}$ and $G^{\mathcal{B}}$, and $ \alpha $ is a parameter that penalize large size solutions: larger the value of $\alpha$, smaller is the optimal contrast-subgraph. The summary graphs $G^{\mathcal{A}}$ and $G^{\mathcal{B}}$ are undirected and weighted graphs, defined over the same set of vertices V as the original observation graphs. A summary graph of a collection of graphs is a single graph where each node (edge) represents at most one node (edge) from each of the graphs it summarizes \cite{6596128}.
\vspace{0.5cm}

\textit{Problem 2} is a symmetric variant, wanting to find a subgraph having the largest absolute difference of edge weights between $G^{\mathcal{A}}$ and $G^{\mathcal{B}}$, so that maximize the contrast-subgraph. 
\vspace{0.5cm}

As said, in this experiment they want to classify people with autism and typically developed people. For this reason they concentrate on the contrast-subgraph ASD-TD is a subgraph dense in the class of ASD and sparse in TD, and the contrast-subgraph TD-ASD is a subgraph dense in TD and sparse in ASD. Calculating constrast-subgraph TD-ASD and ASD-TD from a dataset they used to make experiments, they were able to observe differences between the two graphs.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.8]{Immagini/c-s1.PNG}
	\caption{Top left: TD-ASD Contrast Subgraph. Bottom left: ASD-TD Contrast Subgraph. Right: scatterplot with at x-axis the number of edges induced by TD-ASD, and at y-axis the number of edges induced by ASD-TD, for each patient.}
	\label{fig:diagram6}
\end{figure}
They ended up with Figure \ref{fig:diagram6}, where the top left image is the TD-ASD contrast-subgraph, while the bottom left image is the ASD-TD contrast-subgraph. We can clearly see the patterns differences between the two contrast-subgraphs. Also, from the right part of Figure \ref{fig:diagram6}, we have a scatterplot with number of edges induces by TD-ASD - x axis - and ASD-TD - y axis - for each patient. With these results they ended up with some important rules:
\begin{itemize}
	\item If an individual exhibits more than 62 edges among the 15 vertices of the contrast subgraph ASD-TD, then there are high chances that the individual is affected by ASD;
	\item If the number of edges induced by the contrast subgraph ASD-TD is smaller than half of the number of edges induced by the contrast subgraph TD-ASD, then there are high chances that the individual is not affected by ASD;
	\item If the number of edges induced by the contrast subgraph ASD-TD is smaller than the number of edges induced by the contrast subgraph TD-ASD, then there are high chances that the individual is affected by ASD.
\end{itemize}

They used these two features to make classification, based on SVM, and compared the results with other methods of the literature. At the end they have a single parameter $\alpha$, a very low run-time (less than 30 seconds to extract the constrast-subgraph), a simple explainability, having only two simple features, and high accuracy. 

\paragraph{Unsupervised Network Embedding for Graph Visualization, Clustering and Classification}\
\label{par:2}
\vspace{0.5cm}

A crucial challenge in mining network-based data is to find effective ways to represent or encode graph structures, in order to make themm efficiently exploited by Machine Learning algorithms. L. Gutiérrez et al \cite{GutierrezUn} provide an unsupervised approach to learn embedding representation for a collection of graphs, to use in graph mining tasks. They use an unsupervised neural network on graphs that aims to capture the distribution of the data, to discriminate between different class of networks. With their method, they learn automatically a feature representation of graphs assessing their similarity on an Euclidean space (Figure \ref{fig:diagram11}), focusing on problems defined on networks that account for \textit{node identity}. They evaluate the method in three network mining tasks: graph clustering, graph classification and visualization. We are more interested in graph classification.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.5]{Immagini/Unsupervised.PNG}
	\caption{Feature representation of graphs on an Euclidean space.}
	\label{fig:diagram11}
\end{figure}

Unlike classical distances in the literature, such as \textit{Hamming} and \textit{Jaccard} distances, this approach performs network comparisons directly on a feature space, through a learned non-linear mapping applied to input graphs. It is composed by some blocks. The first is the \textbf{Autoencoder}, that is one of the most popular unsupervised neural network approaches. Unsupervised approaches aim to uncover hidden patterns or learning representations from unlabeled data. In particular, the autoencoder allows to compress the representation of input data, removing redundancy and reducing the dimension of the input. A traditional autoencoder learns a non-linear mapping which encodes an input example in a smaller dimensional latent vector. Unfortunately, this method could just learn the training data, meaning that it will not work on unknown data. For this reason they train a \textbf{Denoising Autoencoder} (\textbf{DAE}) (Figure \ref{fig:diagram12}), that reconstruct a clean or repaired version from corrupted input.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.5]{Immagini/unsupervised2.PNG}
	\caption{Structure of the Denoising Autoencoder (DEA).}
	\label{fig:diagram12}
\end{figure}
 
Giving in input an adjacency matrix to the DEA could be insufficient, so they compute higher powers of the matrix to capture multiple path relationships. Also, this method remains invariant to the node ordering when the same node permutation is assigned to the graph, having a collection of networks with node correspondence across graphs. A main advantage of transforming graphs into feature vectors is that it allows to compare easily networks computing only Euclidean distances between their
embeddings.
\vspace{0.5cm}

For the experiment part, we will see the graph classification results. Their task is to classify connectomes according to gender, male or female. The input is a dataset built from MRI, structural and diffusion, so a collection of graphs. The two steps of the model are learning graph embedding through DAE and computation of a pairwise Euclidean distance matrix. Comparing their method with classic ones of the literature, they saw that it outperformed them, at accuracy level, remaining competitive only with DeltaCon model. Regarding the runtime, it is much faster than all the others.

\paragraph{Supervised classification of structural brain networks reveals gender differences}\
\vspace{0.5cm}

Another work base on statistical fingerprint is the one of Chiem B. et al \cite{8379106}. The work aims to study individual differences in the structural connectome, not the functional one, with perfect node correspondence property. This property means that each node corresponds to the same anatomical location in each connectome. They propose three new methods based on SVM.
\vspace{0.5cm}

The first contribution regards the feature extraction, crucial point for the classification part. They introduced the \textbf{Bag-of-Edges}, it consists in the application of the \textit{Recursive Feature Eliminatio} (RFE). It trains an SVM with linear kernel, sorts features according to the weights granted by the SVM, and reduces the size of the feature vector keeping only a percentage of the most discriminative features. It stops when a given number of features is reached (Figure \ref{fig:diagram13}). At the end we have a feature vector with only the most discriminative edges of the graph.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.8]{Immagini/supervised1.PNG}
	\caption{Structure of the Bag-of-Edges.}
	\label{fig:diagram13}
\end{figure}
 
To take advantage of perfect node property they designed two new graph kernels. First they used the \textbf{DeltaCon Kernel}, introduced by Koutra et al \cite{koutra2013deltacon}, but never used as a kernel. As first step they compute for each graph a node-to-node affinity matrix, that encodes a particular measure of similarity between nodes of the graph. The similarity measure taken in consideration is Fast Belief Propagation (FaBP). Then is defined the DeltaCon kernel similarity between two graphs (Figure \ref{fig:diagram14}). 
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.8]{Immagini/supervised2.PNG}
	\caption{DeltaCon Kernel similarity.}
	\label{fig:diagram14}
\end{figure}

The second graph kernel is the kernel based on \textbf{regularized Laplacian}. It follows the same principle of the DeltaCon kernel, but uses a different similarity measure, the regularized Laplacian.
\vspace{0.5cm}

The experiments aim to classify connectomes, detecting the gender of the brain in input. The method that gave better results is the Bag-of-edges, even if even the other two models performed better than other graph kernels take from the literature. In particular, the DeltaCon kernel worked better with regularized Laplacian similarity.

\paragraph{Sub-network Kernels for Measuring Similarity of Brain Connectivity Networks in Disease Diagnosis}\
\vspace{0.5cm}

The innovation of the literature of B. Jie \cite{Jie2018} is in the fact that they take in consideration both global and local properties of brain regions to construct graph kernels for measuring the similarity of brain networks. They propose a novel sub-network kernel on brain networks for brain decease classification. They first construct a group of sub-networks on each node to reflect the multi-level connectivity properties of brain networks. Then, they define the similarity of a pair of brain networks, by calculating the similarities of all corresponding pairs of sub-network groups when considering the uniqueness of nodes. The total contribution of this work comprehend three steps: a novel sub-network kernel for measuring the similarity between brain networks, a sub-network kernel based learning (SKL) framework for automated brain disease diagnosis based on fMRI data and finally an implementation for performing inference on brain network data.
\vspace{0.5cm}

The proposed \textbf{sub-network kernel based learning} (\textbf{SKL}) framework for brain disease classification in composed by the following steps: 

\begin{enumerate}
	\item Image preprocessing and connectivity network construction;
	\item Network thresholding and sub-network kernel construction;
	\item Classification.
\end{enumerate}

It is illustrated in Figure \ref{fig:diagram15}.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.8]{Immagini/subnetwork1.PNG}
	\caption{Sub-network kernel based learning framework (SKL) structure.}
	\label{fig:diagram15}
\end{figure}

After the preprocess of the images, there is the construction of sub-network kernel. First a group of sub-networks is constructed on each node to reflect the multi-level connectivity properties of the brain. Then is calculated the similarity between brain networks. It is done calculating the similarity of all pairs of sub-networks groups from the same node across different brain networks, since each node on each brain network corresponds to the same ROI. 
\vspace{0.5cm}

The sub-network kernel based Learning starts with a \textit{discrimination} of the nodes to construct more discriminative networks. It is done with \textit{t}-test and a thresholding with \textit{p}-value. The result is a feature vector that represents the discriminative network. Then there is a \textit{network thresholding}, with different thresholds, that will remove edges with zero weights, to reflect the topological properties of discriminative networks. Eventually, having more thresholds, they adopt a \textit{multi-kernel SVM classification} with grid-search approach. Once found the optimal parameters, the traditional SVM can be applied for classification.
\vspace{0.5cm}

Compared with others state-of-the-art kernels, this method performs much better, with higher accuracy and AUC. They also experimented on different parameters. The two parameters to tune are \textit{d}, the number of iterations to compute the mathematical representation of sub-networks, and \textit{h}, the size of a sub-network set. They saw that \textit{h} is very important, because they reached the best performance at $ h = 2 $, while for \textit{d} the method is robust. 
Another important evidence is that, without constructing discriminative networks from the originals brain network, the model is not so accurate compared to the model with it. 

\paragraph{Integration Of Network Topological Features And Graph Fourier Transform For Fmri Data Analysis}\
\vspace{0.5cm}

Very interesting is the new approach of J. Wang et al \cite{8363530}. Their challenge is to evaluate differences of functional connectivity networks between different age groups. The novelty is in the fact that the brain networks are constructed combining commonly used topological features from complex network analysis, with \textbf{Graph Fourier Transform} (GFT). GFT contributes to find the significant subspace of the original signal, so it could be a complementary information, given the fact that topological features reveal the morphological structure of the brain network. 
\vspace{0.5cm}

In \textit{Graph signal}, resting-state fMRI data can be viewed as time series graph signals defined on the parcellated brain regions. On each graph can be computed the GFT, and the eigenvalues are taken in consideration for the construction of the network. To represent the original graph signal, are selected the low frequency components, corresponding to the first several eigenvalues calculated by GFT. 
\vspace{0.5cm}

For the topological features they calculate the \textit{centrality} and the \textit{segregation}. The centrality of the nodes is calculated with two measures, the degree and the betweeness centrality. The segregation refers to the existence of specialized neurons and brain areas, organized into distinct neural populations and grouped together to form segregated cortical areas. Functional segregation in the brain is the ability for specialized processing to occur within these areas. A simple measure of functional segregation is defined based on the number of triangles in the network, with a high number of triangles implying segregation.
\vspace{0.5cm}

To construct the graph, once calculated the topological features, they concatenate the data into a $ 264 \times (TM) $ matrix, where M is the number of subjects. Each row is normalized into a unit norm. To estimate the adjacency matrix is used the Gaussian radial basis functional kernel. Then they can get the features from the frequency domain by GFT. 
\vspace{0.5cm}

After the construction of the input data, they use a regularized least-square regression using lasso algorithm for feature selection. The features are then given to a linear SVM classifier. The results of the experiment gives high accuracy, but they where not compared with other state-of-the-art methods. The steps of the model are illustrate in Figure \ref{fig:diagram16}.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.8]{Immagini/integration.PNG}
	\caption{Steps of the experiment.}
	\label{fig:diagram16}
\end{figure}

\subsection{Machine Learning}
\paragraph{Network Classification With Applications To Brain Connectomics}\
\label{par:3}
\vspace{0.5cm}

The goal of Arroyo-Reliòn at al \cite{Arroyo_Reli_n_2019} is to develop a high-dimensional network classifier that uses all the individual edge weights but also respects the network structure of the data and produces more interpretable results. 
\vspace{0.5cm}

Regarding the network structures they aim to find nodes or subnetworks with good discriminative power, and hence select both the most informative nodes and edges. To capture structural assumptions on important predictive edges, they focus on convex structured sparsity penalties (Bach et al. \cite{bach2012structured}) that encourage a small number of active nodes, meaning nodes attached to at least one edge with a non-zero coefficient. For this purpose they use a group lasso penalty, that eliminate a group of variables simultaneously. To enforce spacial smoothness in the solution, they aim for a regularization that can be applied to any kind of network data.
\vspace{0.5cm}

To solve this penalty problem they use an optimization algorithm with two common approaches to convex optimization, proximal algorithms and alternative direction method of multipliers (ADMM). They use an accelerated version of the proximal algorithm (Beck and Teboulle \cite{beck2009fast}) to solve the main problem. In each step, they need to calculate a proximal operator, which is a further convex optimization problem solved with the ADMM algorithm.
\vspace{0.5cm}

They first experiment their method with synthetic graphs, comparing it with other state-of-the-art models, with some that takes in account the network structure and some that does not. With small number of communities the method outperforms the others in terms of classification. When it is increased, it could be comparable to methods that do not use network structures. The runtime is of an average of ten minutes for this method, while for most of the others is of ours. 
Experimenting on Schizophrenia datasets they outperformed all methods except the SVM model, that has not variable selection. Still it has a very high accuracy, and can also correctly identify brain regions that are suspected to be involved in the study of the Schizophrenia disease. 

\paragraph{Stable Biomarker Identification For Predicting Schizophrenia in the Human Connectome}\
\label{par:4}
\vspace{0.5cm}

Stable Biomarker Identification model \cite{GutierrezBio} is one of the methods we will take in account for the experimentation part. They adopt a machine learning approach that aims at discovering the most relevant set of biomarkers for discriminating subjects groups and thus quantitatively describing the group differences, both in terms of classification accuracy and stability of selected features. 
\vspace{0.5cm}

Biomarkers discovery consists on the identification of regions or connections of interest associated with a neural disorder. From machine learning perspective, the choice of biomarkers can be addressed as a feature selection problem. They perform an automatic feature selection procedure in order to identify biomarkers that are relevant for the diagnosis of schizophrenia from brain connectivity data. As a classifier they use an RFE-SVM, integrated into an embedded feature selection approach. The aim of the present work is threefold:

\begin{itemize}
	\item First, they investigate the effect of structural, functional, and multi-modal (structural+functional) connectome with different resolutions in the classification performance of schizophrenia.
	\item Second, they perform a careful feature selection procedure across modalities in order to assess the robustness of the selected features providing the best trade-off between high accuracy and stability. 
	\item Finally, the analysis of retrieved biomarkers allows to identify a distributed set of brain regions engaged in the discrimination of patients and control subjects.
\end{itemize}  

As we can see in Figure \ref{fig:diagram18} the model has two Cross Validation. The outer CV, represented by the left image, is used to evaluate the performance of the model. The inner CV, at the right part of the image, is used to choose the best parameters for the classification.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.65]{Immagini/stablebiomarkers.PNG}
	\caption{Structure of Stable Biomarkers Identification model}
	\label{fig:diagram18}
\end{figure}

They observed that functional modality gives better performance than structural one, but is less stable. The better performance is given by the multi-modality input, and gives also a good trade-off between good performance and stable biomarkers. They even proceeded with the identification of brain areas involved in the classification of patients and controls.

\paragraph{Multi-modality disease modelling via collective deep matrix factorization}\
\vspace{0.5cm}

This model of Q. Wang et al \cite{10.1145/3097983.3098164} is based on a framework to fuse multiple data modalities for predictive modeling, using deep matrix factorization. In particular, they study three modalities together, two kinds of MRI and genetic data. The first type of MRI is \textbf{T1 MRI}, that capture structural information of grey matter in the brain. The other is the diffusion-weighted MRI (\textbf{dMRI}), that is sensitive to microscopic properties of brain's white matter. So, T1 MRI captures areas composed of neurons while dMRI estimated connections between those area. The genotype impacts the disease in a way that is not directly related to brain structure and function. All these modalities interact in a complicated manner, this suggests that directly combining feature spaces may not lead to effective integration.
\vspace{0.5cm}

To reduce the feature dimensionality while maintaining most information they use \textbf{matrix factorization technique}. Traditional matrix factorizations assume linear interactions between data. This cannot be the case, there are non-linear interactions. They propose a deep matrix factorization framework to fuse information from multiple modalities and transfer predictive knowledge to differentiate patients with mild cognitive impairment (MCI), early stage of Alzheimer, from cognitive normal subjects. They build a non-linear hierarchical deep matrix factorization framework which decomposes each modality into a modality invariant component and a modality specific component, guided by supervision information. 
\vspace{0.5cm}

To fuse multiple data modalities through deep matrix factorization they use a deep neural network to factorize each modality. The structure is illustrated in Figure \ref{fig:diagram17}.
\vspace{0.5cm}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.65]{Immagini/multimodality.PNG}
	\caption{Structure of the deep neural network of Deep Matrix Factorization}
	\label{fig:diagram17}
\end{figure}

The deep neural network serves as highly non linear mapping between the input matrix and the factorized matrix, and projects the latent representations non-linearly to the same latent space. 
They saw that with the fusion of all the three modalities the performance are higher than when they use only one or two modalities, and also outperforms other matrix factorization methods.