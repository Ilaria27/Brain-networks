@inproceedings{lanciano2020cs,
  doi = {10.1145/3394486.3403383},
  url = {https://doi.org/10.1145/3394486.3403383},
  year = {2020},
  month = jul,
  publisher = {{ACM}},
  author = {Tommaso Lanciano and Francesco Bonchi and Aristides Gionis},
  title = {Explainable Classification of Brain Networks via Contrast Subgraphs},
  booktitle = {Proceedings of the 26th {ACM} {SIGKDD} International Conference on Knowledge Discovery {\&} Data Mining}
}


@InProceedings{pmlr-v5-shervashidze09a,
  title = 	 {Efficient graphlet kernels for large graph comparison},
  author = 	 {Shervashidze, Nino and Vishwanathan, SVN and Petri, Tobias and Mehlhorn, Kurt and Borgwardt, Karsten},
  booktitle = 	 {Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {488--495},
  year = 	 {2009},
  editor = 	 {van Dyk, David and Welling, Max},
  volume = 	 {5},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v5/shervashidze09a/shervashidze09a.pdf},
  url = 	 {https://proceedings.mlr.press/v5/shervashidze09a.html},
  abstract = 	 {State-of-the-art  graph kernels do not scale to large graphs with hundreds of nodes and thousands of edges. In this article we propose to compare graphs by counting  \it graphlets, \ie subgraphs with k nodes where k ?{ 3, 4, 5 }. Exhaustive enumeration of all graphlets being prohibitively expensive, we introduce two theoretically grounded speedup schemes, one based on sampling and the second one specifically designed for bounded degree graphs. In our experimental evaluation, our novel kernels allow us to efficiently compare large graphs that cannot be tackled by existing graph kernels.}
}


@article{GutierrezUn,
  doi = {10.1007/s41109-019-0197-1},
  url = {https://doi.org/10.1007/s41109-019-0197-1},
  year = {2019},
  month = oct,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {4},
  number = {1},
  author = {Leonardo Guti{\'{e}}rrez-G{\'{o}}mez and Jean-Charles Delvenne},
  title = {Unsupervised network embeddings with node identity awareness},
  journal = {Applied Network Science}
}

@inproceedings{groupinn,
  author    = {Yujun Yan and
               Jiong Zhu and 
               Marlena Duda and 
               Eric Solarz and
               Chandra Sripada and
               Danai Koutra},
  title     = {GroupINN: Grouping-based Interpretable Neural Network-based Classification of Limited, Noisy Brain Data},
  booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on
               Knowledge Discovery {\&} Data Mining, {KDD} 2019, London, UK,
               August 4-8, 2019},
  year      = {2019},
  }

@article{GutierrezBio,

title = {Stable biomarker identification for predicting schizophrenia in the human connectome},

journal = {NeuroImage: Clinical},

volume = {27},

pages = {102316},

year = {2020},

issn = {2213-1582},

doi = {https://doi.org/10.1016/j.nicl.2020.102316},

url = {https://www.sciencedirect.com/science/article/pii/S2213158220301534},

author = {Leonardo Gutiérrez-Gómez and Jakub Vohryzek and Benjamin Chiêm and Philipp S. Baumann and Philippe Conus and Kim Do Cuenod and Patric Hagmann and Jean-Charles Delvenne},

abstract = {Schizophrenia, as a psychiatric disorder, has recognized brain alterations both at the structural and at the functional magnetic resonance imaging level. The developing field of connectomics has attracted much attention as it allows researchers to take advantage of powerful tools of network analysis in order to study structural and functional connectivity abnormalities in schizophrenia. Many methods have been proposed to identify biomarkers in schizophrenia, focusing mainly on improving the classification performance or performing statistical comparisons between groups. However, the stability of biomarkers selection has been for long overlooked in the connectomics field. In this study, we follow a machine learning approach where the identification of biomarkers is addressed as a feature selection problem for a classification task. We perform a recursive feature elimination and support vector machines (RFE-SVM) approach to identify the most meaningful biomarkers from the structural, functional, and multi-modal connectomes of healthy controls and patients. Furthermore, the stability of the retrieved biomarkers is assessed across different subsamplings of the dataset, allowing us to identify the affected core of the pathology. Considering our technique altogether, it demonstrates a principled way to achieve both accurate and stable biomarkers while highlighting the importance of multi-modal approaches to brain pathology as they tend to reveal complementary information.}
}ù

@inproceedings{GraphClassAtt,
author = {Lee, John Boaz and Rossi, Ryan and Kong, Xiangnan},
title = {Graph Classification Using Structural Attention},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219980},
doi = {10.1145/3219819.3219980},
abstract = {Graph classification is a problem with practical applications in many different domains.
To solve this problem, one usually calculates certain graph statistics (i.e., graph
features) that help discriminate between graphs of different classes. When calculating
such features, most existing approaches process the entire graph. In a graphlet-based
approach, for instance, the entire graph is processed to get the total count of different
graphlets or subgraphs. In many real-world applications, however, graphs can be noisy
with discriminative patterns confined to certain regions in the graph only. In this
work, we study the problem of attention-based graph classification. The use of attention
allows us to focus on small but informative parts of the graph, avoiding noise in
the rest of the graph. We present a novel RNN model, called the Graph Attention Model
(GAM), that processes only a portion of the graph by adaptively selecting a sequence
of "informative" nodes. Experimental results on multiple real-world datasets show
that the proposed method is competitive against various well-known methods in graph
classification even though our method is limited to only a portion of the graph.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1666–1674},
numpages = {9},
keywords = {reinforcement learning, attentional processing, graph mining, deep learning},
location = {London, United Kingdom},
series = {KDD '18}
}

@article{Rogers2010ECFP,
  abstract = { Extended-connectivity fingerprints (ECFPs) are a novel class of topological fingerprints for molecular characterization. Historically, topological fingerprints were developed for substructure and similarity searching. ECFPs were developed specifically for structure-activity modeling. ECFPs are circular fingerprints with a number of useful qualities: they can be very rapidly calculated; they are not predefined and can represent an essentially infinite number of different molecular features (including stereochemical information); their features represent the presence of particular substructures, allowing easier interpretation of analysis results; and the ECFP algorithm can be tailored to generate different types of circular fingerprints, optimized for different uses. While the use of ECFPs has been widely adopted and validated, a description of their implementation has not previously been presented in the literature. },
  added-at = {2017-02-22T23:03:16.000+0100},
  author = {Rogers, David and Hahn, Mathew},
  biburl = {https://www.bibsonomy.org/bibtex/2a4983270b96f6f357bb69c3b7e267038/salotz},
  description = {Extended-Connectivity Fingerprints - Journal of Chemical Information and Modeling (ACS Publications)},
  doi = {10.1021/ci100050t},
  eprint = {http://dx.doi.org/10.1021/ci100050t},
  interhash = {fe8c057b062de3cf75a08cc0cef8f867},
  intrahash = {a4983270b96f6f357bb69c3b7e267038},
  journal = {Journal of Chemical Information and Modeling},
  keywords = {chemoinformatics graph-theory molecular-descriptors molecule-topological-descriptors},
  note = {PMID: 20426451},
  number = 5,
  pages = {742-754},
  timestamp = {2017-02-22T23:03:16.000+0100},
  title = {Extended-Connectivity Fingerprints},
  url = {http://dx.doi.org/10.1021/ci100050t},
  volume = 50,
  year = 2010
}

@inproceedings{NIPS2015_f9be311e,
 author = {Duvenaud, David K and Maclaurin, Dougal and Iparraguirre, Jorge and Bombarell, Rafael and Hirzel, Timothy and Aspuru-Guzik, Alan and Adams, Ryan P},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Convolutional Networks on Graphs for Learning Molecular Fingerprints},
 url = {https://proceedings.neurips.cc/paper/2015/file/f9be311e65d81a9ad8150a60844bb94c-Paper.pdf},
 volume = {28},
 year = {2015}
}



@article{ZHOU202057,
title = {Graph neural networks: A review of methods and applications},
journal = {AI Open},
volume = {1},
pages = {57-81},
year = {2020},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2021.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666651021000012},
author = {Jie Zhou and Ganqu Cui and Shengding Hu and Zhengyan Zhang and Cheng Yang and Zhiyuan Liu and Lifeng Wang and Changcheng Li and Maosong Sun},
keywords = {Deep learning, Graph neural network},
abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.}
}

